---
title: "Bayesian networks in R"
author: "Simon Dirmeier <simon.dirmeier@bsse.ethz.ch>"
date: "17. January 2020"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: default
      highlightLanguage: R
      ratio: '16:9'

---

<style type="text/css">
@import url(https://fonts.googleapis.com/css?family=Raleway:400,300,600);

h1, h2, h3 {
  font-family: 'Raleway';
}

.title-slide, .title-slide h1, .title-slide h3 {
  color: black;
  background-color: white;
  text-shadow: none;
  font-family: 'Raleway';
  text-align: left;
}

.title-slide h1 {
  margin-top: 30%;
}

.remark-slide-content {
  font-size: 30px;
  font-family: 'Raleway';
}

a, a code {
  color: maroon;
}

.left-column {
  width: 50%;
  height: 92%;
  float: left;
  color: black;
  padding-top: 0em;
}

.right-column {
  width: 50%;
  height: 92%;
  float: right;
  color: black;
  padding-top: 0em;
}

.mjx-chtml {
  font-size: 30px !important;
  color: black;
}

.onethirdcolumn, .onethirdcolumnborder {
  margin-left: 5px;
  margin-right: 5px;
  width: 30%; 
  height: 92%;
  float: left; 
  color: black;
  padding-top: 0em;
  box-sizing: border-box;
}

.onethirdcolumnborder {
  border-style: solid;
  border-width: 0px 1px 0px 1px;
}

.centeredtwo {
  margin: auto;
  width: 50%;
  height: 92%;
  color: black;
  padding-top: 0em;
  box-sizing: border-box;
  margin: auto;
  text-align: center;
}

body {
  color: black;
}

.small .remark-code {
  font-size: 50% !important;
}

.small {
  font-size: 85% !important;
}


</style>

```{r setup, include=FALSE, echo=FALSE, message=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.width=5, fig.height=3, fig.align = "center", message=FALSE, warning = FALSE, dpi=720) 

library(magrittr)
library(ggplot2)
library(tibble)

library(ggdag)
library(dagitty)
library(bnlearn)

dag <- dagitty::dagitty('dag {
    RAF [pos="2,2"]
    MEK [pos="2,1"]
    PIP3 [pos="1,0"]
    PIP2 [pos="1,1"]
    PLCG [pos="0,2"]

    RAF -> PIP2 <- PLCG
    PIP2 -> PIP3
    RAF -> MEK
}')

empty.dag <- ggdag::tidy_dagitty(dag)
empty.dag$data$direction <- NA
empty.dag$data$to <- NA
empty.dag$data$xend <- NA_integer_
empty.dag$data$yend <- NA_integer_

cat.signalling.data <- readRDS("../data/signalling_data-categorical.rds")
signalling.data <- readRDS("../data/signalling_data.rds")
data <- cat.signalling.data
normal.data <- signalling.data

bn <- empty.graph(colnames(cat.signalling.data))
arcs(bn) <- dagitty::edges(dag)[,1:2] %>%
  dplyr::mutate(v = as.character(v), w = as.character(w)) %>%
  dplyr::rename(from=v, to=w)
bn_fit <- bn.fit(bn, cat.signalling.data)
bn_fit.gaussian <- bn.fit(bn, signalling.data)
```

# Before we start

- We will use `R` for learning Bayesian networks from data.
- If you want to follow the tutorials on your laptop, you need some packages. Install them using:

```{r, eval=FALSE}
install.packages(
  c("bnlearn", "ggraph", "igraph")
)
```

- If you want to do them at some point later, the `R` tutorials can be found on: [bit.ly/bayesian-networks](http://bit.ly/bayesian-networks)
- Slides: [bit.ly/bayesian-networks-slides](http://bit.ly/bayesian-networks-slides)

---

# What are Bayesian networks

.right-column[
```{r, echo=FALSE, dpi=1200}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```

$$\begin{align}
P(\cdot \mid \theta, G)  = & \, P(\text{PLCG}) \cdot P(\text{RAF}) \\ & \cdot P(\text{MEK} \mid \text{RAF}) \\ & \cdot P(\text{PIP2} \mid \text{RAF}, \text{PLCG}) \\ & \cdot P(\text{PIP3} \mid \text{PIP2})
\end{align}$$
]

.left-column[
A Bayesian network is a probability distribution $P$ of a multivariate random variable that factorizes w.r.t. a directed acyclic graph.

- nodes: random variables $X_i$
- edges: conditional dependencies
- factorization: $P(X \mid \theta, G) = \prod_i P(X_i \mid \mathbf{pa}_i)$
]

---

# A BN of dependent genes

.right-column[
```{r, echo=FALSE, dpi=1200}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```
]

.left-column[
Dependent gene expression levels
```{r}
head(data)
```
]

---

# A BN of dependent genes

Usually the structure of the BN is not known. <br>We need to learn the edges and fit the parameters $\theta$.

.centeredtwo[
```{r, echo=FALSE}
ggdag::ggdag(empty.dag) + 
  ggplot2::theme_void()
```
]

---

# Let's learn a BN from data
## What do we need ?

- A research question (i.e., does MEK regulate RAF expression)
- Data 
- A method for learning the structure:
  - Score-based learning (e.g., using BIC as score)
  - Constraint-based learning (i.e., using CI)
- A method for inferring parameters: MAP or MLE
- Understanding what the learned BN *can* tell us

---

# Discrete Bayesian networks

.right-column[
```{r, echo=FALSE, dpi=1200}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```
]

.left-column[
Dependent gene expression levels (multinomial variables)
```{r}
head(data)
```
]

---

# Discrete Bayesian networks

.right-column[
```{r, echo=FALSE, dpi=1200, out.width = '60%'}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```

$$\small \begin{align}
P(\cdot \mid \theta, G)  = & \, P(\text{PLCG}) \cdot P(\text{RAF}) \\ & \cdot P(\text{MEK} \mid \text{RAF}) \\ & \cdot P(\text{PIP2} \mid \text{RAF}, \text{PLCG}) \\ & \cdot P(\text{PIP3} \mid \text{PIP2})
\end{align}$$

]

.left-column[

.small[
Local parameters of MEK:
```{r, echo=FALSE, out.width = '80%'}
bn.fit.dotplot(bn_fit$MEK, main = NULL, xlab = NULL, ylab=NULL)
```

Estimated from data:
```{r}
raf_high <- sum(data$RAF == "High")
mek_med_raf_high <- sum(data$MEK == "Medium" & 
                        data$RAF == "High")
mek_med_raf_high / raf_high
```
]

]

---

# Discrete Bayesian networks

Local parameters of PIP2
```{r, echo=FALSE, out.width = '80%', fig.width=10, fig.height=5}
bn.fit.dotplot(bn_fit$PIP2, main = NULL, xlab = "P(PIP2 | PLCG, RAF)", ylab=NULL)
```

---

# Gaussian Bayesian networks

.right-column[
```{r, echo=FALSE, dpi=1200}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```
]

.left-column[
Dependent gene expression levels (normal variables)
```{r}
head(normal.data)
```
]

---

# Gaussian Bayesian networks

.right-column[
```{r, echo=FALSE, dpi=1200, out.width = '60%'}
ggdag::ggdag(dag) + 
  ggplot2::theme_void()
```

$$\small \begin{align}
P(\cdot \mid \theta, G)  = & \, P(\text{PLCG}) \cdot P(\text{RAF}) \\ & \cdot P(\text{MEK} \mid \text{RAF}) \\ & \cdot P(\text{PIP2} \mid \text{RAF}, \text{PLCG}) \\ & \cdot P(\text{PIP3} \mid \text{PIP2})
\end{align}$$

]

.left-column[

.small[
Local parameters of MEK:
```{r, eval=FALSE}
> bn_fit$MEK

Conditional density: MEK | RAF
Coefficients:
 (Intercept)           RAF  
-0.003345871  -0.286159395
```

Estimated from data:
```{r, eval=FALSE}
> lm(MEK ~ RAF, data=data)

Call: lm(formula = MEK ~ RAF, data = data)

Coefficients:
(Intercept)          RAF  
  -0.003346    -0.286159  
```
]

]

---

# Score-based learning

Search space of DAGs and find the one that maximizes a score, e.g. BIC: $\text{score}(G) = \log P(D \mid \hat{\theta}, G) - \frac{\nu}{2} \log n$

.onethirdcolumn[

```{r, echo=FALSE}
ggdag::ggdag(empty.dag) + ggplot2::theme_void()
```

```{r, eval=FALSE}
> score(graph, data)
[1] -200
```
]

.onethirdcolumnborder[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    RAF [pos="2,2"]
    MEK [pos="2,1"]
    PIP3 [pos="1,0"]
    PIP2 [pos="1,1"]
    PLCG [pos="0,2"]
    
    PIP2 -> PIP3 <- PLCG
    MEK <- RAF
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```

```{r, eval=FALSE}
> score(graph, data)
[1] 1
```
]

.onethirdcolumn[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    RAF [pos="2,2"]
    MEK [pos="2,1"]
    PIP3 [pos="1,0"]
    PIP2 [pos="1,1"]
    PLCG [pos="0,2"]
    
    RAF -> PIP2 -> PIP3 <- PLCG
    MEK <- RAF -> PLCG
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```

```{r, eval=FALSE}
> score(graph, data)
[1] 10
```
]

---

# Constraint-based learning

Test conditional independence of pairs of variables.

.right-column[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    RAF [pos="2,2"]
    MEK [pos="2,1"]
    PIP3 [pos="1,0"]
    PIP2 [pos="1,1"]
    PLCG [pos="0,2"]
    
    PIP3 <-> PLCG
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```

]

.left-column[
Are PIP3 and PLCG marginally independent?
```{r, eval=FALSE}
> ci.test("PIP3", "PLCG", data)

data:  PIP3 ~ PLCG  
x2 = 22.44, df = 4, p-value = 0.0001638
```
]

---

# Constraint-based learning

Remove edges if variables are conditionally independent.

.right-column[
```{r, echo=FALSE}
ggdag::ggdag(empty.dag) + ggplot2::theme_void()
```
]

.left-column[
Are PIP3 and PLCG conditionally independent?
```{r, eval=FALSE}
> ci.test("PIP3", "PLCG", 
          c("PIP2", "RAF", "MEK"), data)

data:  PIP3 ~ PLCG | PIP2 + RAF + MEK
x2 = 90.678, df = 108, p-value = 0.8854
```
]

---

# Things to consider

Cannot (generally) learn direction of edges from observational data. All three DAGs have same score and encode same CIs!

.onethirdcolumn[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    Z [pos="2,2"]
    Y [pos="1,1"]
    X [pos="0,2"]
    
    X -> Y -> Z
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```
]

.onethirdcolumn[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    Z [pos="2,2"]
    Y [pos="1,1"]
    X [pos="0,2"]
    
    X <- Y <- Z
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```
<br><br>
$X \not\!\perp\!\!\!\perp Z$, $X \perp\!\!\!\perp Z \mid Y$
]

.onethirdcolumn[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    Z [pos="2,2"]
    Y [pos="1,1"]
    X [pos="0,2"]
    
    X <- Y -> Z
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```
]

---

# Things to consider

*Can* learn direction of immorality.

.centeredtwo[
```{r, echo=FALSE}
dagitty::dagitty('dag {
    Z [pos="2,2"]
    Y [pos="1,1"]
    X [pos="0,2"]
    
    X -> Y <- Z
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```
<br><br>
$X \perp\!\!\!\perp Z$, $X \not\!\perp\!\!\!\perp Z \mid Y$
]

---

# Examples

.left-column[

```{r, echo=FALSE}
ggdag::ggdag(dag) + ggplot2::theme_void()
```

```{r, eval=FALSE}
> score(dag1, data)
[1] -2589.816
```
]

.right-column[
```{r, echo=FALSE}
dagitty('dag {
  RAF [pos="2,2"]
  MEK [pos="2,1"]
  PIP3 [pos="1,0"]
  PIP2 [pos="1,1"]
  PLCG [pos="0,2"]

  RAF -> PIP2 <- PLCG
  PIP2 -> PIP3
  RAF <- MEK
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```

```{r, eval=FALSE}
> score(dag2, data)
[1] -2589.816
```
]

---

# Markov equivalence class

Can only learn a BN up to its *Markov equivalence class*, i.e. the *completed partially directed acycled graph*.
.left-column[
```{r, echo=FALSE}
dagitty('dag {
  RAF [pos="2,2"]
  MEK [pos="2,1"]
  PIP3 [pos="1,0"]
  PIP2 [pos="1,1"]
  PLCG [pos="0,2"]

  RAF -> PIP2 <- PLCG
  PIP2 -> PIP3
  RAF <-> MEK
}') %>% ggdag::ggdag() + ggplot2::theme_void()
```
]
.right-column[
**Crucial detail!** Remember this when interpreting the structure of a BN. Edges can be deceiving and in some cases turned around.
- **no** causal interpretation
- **only** conditional dependence
]

---

# Let's learn a BN from data
## R tutorial 1

- Load the data: `data/singalling_data-categorical.rds`.
- Learn the structure of a BN using:
    - `bnlearn::tabu`
    - `bnlearn::pc.stable`
  Are there any differences ?  
- Compute the equivalence class of the learned DAGs (`bnlear::cpdag`)
- Make a query: $P(\text{MEK} = \text{high} \mid \text{RAF} = \text{low})$ (`bnlearn::cpquery`)

---

# Let's learn a BN from data
## R tutorial 2

- Read the data (`data/singalling_data.rds`) into `R`.
- Learn the structure of a BN using
    - `bnlearn::tabu`
- Compute the equivalence class of the learned DAGs (`bnlear::cpdag`)
- What do the coefficients mean?
- Make a query: $P(\text{MEK} = \text{high} \mid \text{RAF} = \text{low})$ (`bnlearn::cpquery`)

---

# Let's learn a BN from data
## R tutorial 3

- Get some confidence in the learned edges. Use `bnlearn::boot.strength` to assess edge strength.
- Plot the network using
  - `plot(average.network(...))`
  - `plot.bootstrapped`

---

# R packages

- Structure learning: `bnlearn` and `pcalg`

- Causal reasoning: `dagitty` and `ggdag`

- Visualization: `ggraph`


---

# References

- Marco Scutari and  Jean-Baptiste Denis, *Bayesian networks with examples in R* (applied)

- David Barber, *Bayesian Reasoning and Machine Learning* (free, theory, good intro) 

- Daphne Kollerand Nir Friedman,  *Probabilistic Graphical Models* (very exhaustive)

<div>
  <div style="float: right; padding: 5px">
  <img src="https://mitpress.mit.edu/sites/default/files/styles/large_book_cover/http/mitp-content-server.mit.edu%3A18180/books/covers/cover/%3Fcollid%3Dbooks_covers_0%26isbn%3D9780262013192%26type%3D.jpg?itok=BDzWXp-V" height="150"/>
  </div>
  <div style="float: right; padding: 5px">
    <img src="http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/jacket.gif" height="150"/>
  </div>
  <div style="float: right; padding: 5px">
    <img src="http://bnlearn.com/images/crc.jpg" height="150"/>
  </div>
</div>

---
